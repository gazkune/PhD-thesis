\section{Data-Driven Approaches}
\label{sec:soa:datadriven}

Data-driven activity modelling can be classified into two main categories: generative and discriminative. The generative approach attempts to build a complete description of the input or data space, usually with a probabilistic model such as a Bayesian network. In contrast, the discriminative approach only models the mapping from inputs (data) to outputs (activity labels). Discriminative approaches include many heuristic (rule-based) approaches, neural networks, conditional random fields and linear or non-linear discriminative learning (e.g. support vector machines). Results using each of those methods are covered in the following.

\subsection{Generative modelling}

The simplest possible generative approach is the Na\"ive Bayes classifier, which has been used with promising results for activity recognition \cite{Bao2004} \cite{Brdiczka2007} \cite{Cook2009} \cite{Tapia2004} \cite{Kasteren2007} \cite{Maurer2006a}. Na\"ive Bayes classifiers model all observations (e.g. sensor readings) as arising from a common causal source: the activity, as given by a discrete label. The dependence of observations on activity labels is modeled as a probabilistic function that can be used to identify the most likely activity given a set of observations. Despite the fact that these classifiers assume conditional independence of the features, the classifiers yield good accuracy when large amounts of sample data are provided. Nevertheless, Na\"ive Bayes classifiers do not explicitly model any temporal information, usually considered important in activity recognition.

The Hidden Markov Model (HMM) is probably the most popular generative approach that includes temporal information. A HMM is a probabilistic model with a particular structure that makes it easy to learn from data, to interpret the data once a model is learned, and is both easy and efficient to implement. It consists of a set of hidden (latent) states coupled in a stochastic Markov chain, such that the distribution over states at some time depends only on the values of states at a finite number of preceding times. The hidden states then probabilistically generate observations through a stochastic process. HMMs made their impact initially through use in the speech recognition literature, where latent states correspond to phoneme labels, and observations are features extracted from audio data. HMMs have more recently been adopted as a model of choice in computer vision for modelling sequential (video) data (see \cite{Gavrila1999} \cite{Moeslund2006} for surveys and \cite{Galata1999} \cite{Starner1995} for early examples). HMMs use a Markov chain over a discrete set of states. A closely relative of the HMM uses continuous states, a model usually referred to as a linear dynamical system (LDS). State estimation in LDSs is better known as a Kalman filter. LDSs have been used with inputs from a variety of sensors for physiological condition monitoring \cite{Quinn2009} in which a method is also introduced to deal with unmodelled variations in data, one of the major shortcomings of the generative approach.

HMMs form the basis of statistical temporal models. They are, in fact, a special case of the more general dynamic Bayesian networks (DBNs), which are Bayesian networks in which a discrete time index is explicitly represented. Inference and learning in DBNs is simply an application of network propagation in Bayesian networks. DBNs usually make a Markovian assumption, but explicitly represent conditional independencies in the variables, allowing for more efficient and accurate inference and learning. A well known early use of DBNs for activity monitoring was in the \textit{Lumi\'ere} project, where a Microsoft Windows user’s need for assistance was modelled based on their activities on the screen \cite{Horvitz1998}.

A simple DBN extension of HMMs is the coupled HMM for recognition of simultaneous human actions (e.g. pedestrian motions \cite{Brand1997}). Coupled Hidden Markov Models (CHMMs) have two Markovian chains, each modelling a different stream of data, with a coupling between them to model their inter-dependence. Oliver et al. \cite{Oliver2004} learn a multi-layer model of office activity to choose actions for a computational agent. The model uses multimodal inputs, making only very slight use of computer vision. The Assisted Cognition project \cite{Kautz2002} has made use of DBNs, in particular for Opportunity Knocks \cite{Liao2007a}, a system designed to provide directional guidance to a user navigating through a city. This system uses a three level hierarchical Markov model represented as a DBN to infer a user’s activities from GPS sensor readings. Movement patterns, based on the GPS localization signals, are translated into a probabilistic model using unsupervised learning. From the model and the user’s current location, future destinations and the associated mode of transportation can be predicted. Based on the prediction, the system has the ability to prompt the user if an error in route is detected.

Wilson and Atkeson use DBNs to simultaneously track persons and model their activities from a variety of simple sensors (motion detectors, pressure sensors, switches, etc.) \cite{Wilson2005}. DBNs were also used in the iSTRETCH system, a haptic robotic device to assist a person with stroke rehabilitation \cite{Kan2011}. The DBN models the person’s current behaviours, their current abilities, and some aspects of their emotional state (e.g. their responsiveness, learning rate and fatigue level). The person’s behaviours correspond to how long they take for each exercise, what type of control they exhibit and whether they compensate. These behaviours are inferred from sensors on the device and in the person’s chair.

Even though they are simple and popular, HMMs and DBNs have some limitations. A HMM is incapable of capturing long-range or transitive dependencies of the observations due to its very strict independence assumptions (on the observations). Furthermore, without significant training, a HMM may not be able to recognise all of the possible observation sequences that can be consistent with a particular activity.

\subsection{Discriminative modelling}

A drawback of the generative approach is that enough data must be available to learn the complete probabilistic representations that are required. In this section, we discuss an alternative approach for modelling in which we focus directly on solving the classification problem, rather than on the representation problem. The complete data description of a generative model induces a classification boundary, which can be seen by considering every possible observation and applying the classification rule using inference. The boundary is thus implicit in a generative model, but a lot of work is necessary to describe all the data to obtain it. A discriminative approach, on the other hand, considers this boundary to be the primary objective.

Perhaps the simplest discriminative approach is Nearest Neighbour (NN), in which a novel sequence of observations is compared to a set of template sequences in a training set, and the most closely matching sequences in the training set vote for their activity labels. This simple approach can often provide very good results. Bao and Intille investigated this method along with numerous other base-level classifiers for the recognition of activities from accelerometer data \cite{Bao2004}. They found that the simple nearest neighbour approach is outperformed by decision trees, a related method, where the training data is partitioned into subsets according to activity labels and a set of rules based on features of the training data. The rules can then be used to identify the partition (and hence the activity label) corresponding to a new data sample. Maurer et al. \cite{Maurer2006a}, employed decision trees to learn logical descriptions of activities from complex sensor readings from a wearable device (the eWatch). The decision tree approach offers the advantage of generating rules that are understandable by the user, but it is often brittle when high precision numeric data is collected. Stikic and Schiele use a clustering method in which activities are considered as a “bag of features” to learn template models of activities from data with only sparse labels \cite{Stikic2009}. 

Many discriminative approaches explicitly take into account the fact that, for classification, it is actually only the points closest to the boundary that are of interest. The ones very far away (the “easy” ones to classify) do not play such a significant role. The challenge is therefore to find these “hard” data points (the ones closest to the boundary). These data points will be known as the “support vectors”, and actually define the boundary. A support vector machine (SVM) is a machine learning technique to find these support vectors automatically. A recent example of an SVM in use for activity modelling is presented by Brdiczka et al. \cite{Brdiczka2009} where a model of situations is learned automatically from data by first learning roles of various entities using SVMs and labelled training data, then using unsupervised clustering to build ’situations’ or relations between entities, which are then labelled and further refined by end users. The key idea in this work is to use a cognitive model (situation model) based on cognitive theory motivated by models of human perception of behaviour in an environment. The CareMedia project \cite{Chen2005} also uses an SVM to locate and recognise social interactions in a care facility from multiple sensors, including video and audio. The fusion of video and audio allowed 90\% recall and 20\% precision in identifying interactions including shaking hands, touching, pushing and kicking. The CareMedia project’s goals are to monitor and report behaviour assessments in a care home to caregivers and medical professionals.

Ravi et al. also found that SVMs performed consistently well, but also investigated meta-level classifiers that combined the results of multiple base-level classifiers \cite{Ravi2005}. Features extracted from worn accelerometers are extracted and classified using five different base-level classifiers (decision tables, decision trees, k-nearest neighbours, SVM and Na\"ive Bayes). The meta-level classifiers are generated through a variety of techniques such as boosting, bagging, voting, cascading and stacking. For recognising a set of eight activities including standing, walking, running, going up/down stairs, vacuuming and teeth brushing, they found that a simple voting scheme performed the best for three easier experimental settings, whereas boosted SVM performed best for the most difficult setting (test/training separation across users and days)

In practice, many activities may have non-deterministic natures, where some steps of the activities may be performed in any order, and so are concurrent or interwoven. A conditional random field (CRF) is a more flexible alternative to the HMM that addresses such practical requirements. It is a discriminative and generative probabilistic model that represents the dependence of a hidden variable $y$ on an observed variable $x$ \cite{Sutton2007}. Both HMMs and CRFs are used to find a sequence of hidden states based on observation sequences. Nevertheless, instead of finding a joint probability distribution $p(x,y)$ as the HMM does, a CRF attempts to find only the conditional probability $p(y|x)$. A CRF allows for arbitrary, non-independent relationships among the observation sequences, hence the added flexibility. Another major difference is the relaxation of the independence assumptions, in which the hidden state probabilities may depend on the past and even future observations. A CRF is modelled as an undirected acyclic graph, flexibly capturing any relation between an observation variable and a hidden state. CRFs are applied to the problem of activity recognition in \cite{Vail2007} where they are compared to HMMs, but only in a simple simulated domain. Liao et al. use hierarchical CRFs for modeling activities based on GPS data \cite{Liao2007}. Hu and Yang use skip-chain CRFs, an extension in which multiple chains interact in a manner reminiscent of the CHMM, to model concurrent and interleaving goals \cite{Hu2008}, a challenging problem for activity recognition. Mahdaviani and Choudhury show how semi-supervised CRFs can be used to learn activity models from wearable sensor data \cite{Mahdaviani2008}.

\subsection{Other approaches}

Many approaches do not fall clearly into discriminative or generative categories, but rather use a combination of both, along with some heuristic information. The Independent Lifestyle Assistant (ILSA) is an example, as it uses a combination of heuristic rules and statistical models of sequential patterns of sensor firings and time intervals to help a person with planning and scheduling \cite{Guralnik2002}. PEAT (the Planning and Execution Assistant and Trainer) is a cognitive assistant that runs on a mobile device, and helps compensate for executive functional impairment. PEAT uses reactive planning to adjust a user’s schedule based on their current activities. Activity recognition in PEAT is based on what the user is doing, and on data from sensors on the mobile device. These are fed into a HMM, the outputs of which are combined with the reactive planning engine \cite{Modayil2008}.

Other work has investigated how activities can be modelled with a combination of discriminative and generative approaches \cite{Lester2005}, how common sense models of everyday activities can be built automatically using data mining techniques \cite{Pentney2008} \cite{Pentney2007}, and how human activities can be analysed through the recognition of object use, rather than the recognition of human behaviour \cite{Wu2007}. This latter work uses DBNs to model various activities around the home, and a variety of radio frequency identification (RFID) tags to bootstrap the learning process. Some authors have attempted to compare discriminative and generative models \cite{Bao2004} \cite{Ravi2005}, generally finding the discriminative models yield lower error rates on unseen data, but are less interpretable. Gu et al. use the notion of emerging patterns to look for frequent sensor sequences that can be associated with each activity as an aid for recognition \cite{Gu2009}. Omar et al. present a comparative study of a variety of classification methods for analysing multi-modal sensor data from a smart walker \cite{Omar2010}.

% Rashidi and Cook's work could go here
One of the biggest problems of data-driven approaches, regardless their category, is the need of large-scale labelled data bases. This problem arises because activity recognition is posed as a supervised learning problem. However, due to the required effort and time for annotating activity data bases, supervised methods do not scale up well in practice. Annotating activity data imposes a burden on annotators and users and often introduces a source of error in the process. Rashidi and Cook show how to overcome the problem of depending on labelled activity data bases in \cite{Rashidi2011}, improving the approach in \cite{Rashidi2013}. They use a non-labelled data base, where they extract activity clusters using non-supervised learning techniques. More concretely, they develop a new activity discovery method named COM, which stands for Continuous, varied Order, Multi Threshold. COM not only discovers discontinuous patterns and their variations, but is able to better handle real life data by dealing with different frequencies/sensor problem. All patterns discovered by COM are then used as inputs for a hierarchical agglomerative clustering algorithm. The clustering algorithm aims at grouping those sensor patterns which are similar in terms of their structure. An activity structure is defined as the start time, duration and region or location. Those clusters are finally used to train a boosted HMM, which is shown to be able to recognise discovered activities. 

Rashidi and Cook bring a new paradigm to data-driven activity recognition in their works, showing the real possibility of using an unsupervised model and avoid data base annotation problems. However, their approach still suffers some other traditional problems of data-driven approaches. Firstly, even though they do not use labelled data bases, they do not overcome the \textit{cold-start} problem, since they have to collect data in order to discover activities and train HMMs. Besides, as other data-driven approaches, they have many difficulties when generalising what they have discovered and learned from previous users, since every user has his/her own ways of performing activities. The price to pay for avoiding labelled data bases is that the approach cannot set activity granularity and that discovered activities do not have any semantic meaning. The first problem refers to the impossibility of deciding at design phase what kind of activities will be recognised. For example, if a user usually washes dishes after preparing meal, COM will discover this sequence as a typical activity. However, the discovered activity is actually a sequence of two lower-grain activities. The second problem refers to the fact that discovered activities are only sequences of sensors with their location and time information, but without any semantic meaning. A human expert is needed afterwards to interpret discovered activities and label them with semantic tags. Notice that this \textit{a posteriori} labelling step may be difficult since activity granularity is not set. 

% Finish with advantages and drawbacks of those approaches

\subsection{Summary of data-driven approaches}

Data-driven approaches have been extensively used for activity recognition. Their advantages and disadvantages are very well known by the scientific community (a summary and comparison to knowledge-driven approaches can be found in Table \ref{tab:soa:comparison}):

\subsubsection*{Advantages}
\begin{itemize}
 \item Uncertainty modelling: as probabilistic and statistical activity modelling is used, data-driven approaches are very good modelling sensor uncertainty. As sensors do not provide certain information and are exposed to failures, modelling uncertainty is a very important feature for real-world deployments.
 \item Temporal information modelling: activity models such as DBNs, HMMs and similar implicitly model temporal information of activities, such as time lapses between two sensor readings, activity duration or activity start time. Time information can be learned from data in a natural way.
 \item Introduce heuristics: discriminative approaches make possible introducing heuristics about activity models. Heuristics can be used to insert basic knowledge about activities and avoid making activity models totally dependent on data.
 \item Dynamic activity models: as learning is a continuous process, activity models evolve as the user changes its habits. As such, activity models are dynamic.
 \item Personal activity models: learning activity models directly over user data, makes activity models personalised. This means that activity models capture the particular way of performing an activity by a user.
\end{itemize}

\subsubsection*{Disadvantages}
\begin{itemize}
 \item ``Cold start'' problem: data is needed to model activities. The dependency with data arises the ``cold start'' problem, since data-driven techniques cannot work immediately after deployment. A data collecting and activity model training process is required for every user.
 \item Lack of reusability: as activity models are directly learned from concrete user data, they cannot generally be used for other users. The main problem is that data-driven approaches cannot build generic activity models, only personal activity models.
 \item Dataset annotation problems: if annotated datasets are needed (supervised learning approaches), scalability becomes a real problem, since the effort required for annotation is huge and annotation methods are prone to errors. If annotated datasets are not used (unsupervised approach), activity granularity and activity semantics is lost. 
\end{itemize}

