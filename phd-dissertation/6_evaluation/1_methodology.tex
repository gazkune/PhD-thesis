\section{Evaluation Methodology}
\label{sec:evaluation:methodology}

% Talk about standard evaluation methodology and its drawbacks
Even though activity recognition is very diverse in terms of sensor approaches and algorithmic choices, evaluation is usually carried out applying a very well known methodology:

\begin{enumerate}
 \item Choose a target environment and deploy sensors to acquire and process information about human activities. 
 \item Select a group of persons who can perform target activities in the prepared environment.
 \item Select a dataset labelling system so datasets generated by users can be used as a ground truth.
 \item Run experiments with users and label obtained activity datasets.
 \item Use the same datasets to test the activity recognition system and store the labels produced by it.
 \item Compare the labels of the activity recognition system with the ground truth using appropriate metrics.
\end{enumerate}

% Insert a diagram that shows the standard methodology

Each of the enumerated steps may vary depending on the activity recognition approach and the available resources. The described methodology, which will be called \textit{standard methodology} for the rest of the paper, is the reference for any group working on human activity recognition.

Nevertheless, there are some problems that make very difficult to implement the standard methodology. For instance, (i) it is not always possible to own an environment and install sensors and processing systems, due to economic reasons, (ii) running experiments with human beings imply ethical and legal issues that can slow down the research process, and (iii) dataset labelling systems are not perfect, since most of them rely on users' memory or discipline to annotate every activity carried out. 

This paper presents a novel evaluation methodology to overcome the enumerated problems. The methodology has been named \textit{hybrid} because it combines real users' inputs and simulation tools. The key idea is to circulate surveys among target users with the objective of capturing how they perform certain activities of daily living. Using the information collected by surveys, individual scripts are prepared, which are then processed by a synthetic dataset generator tool to simulate arbitrary number of days and generate perfectly labelled datasets of activities. To get as close as possible to real world settings, the synthetic dataset generator uses probabilistic sensor noise models and probabilistic time lapses.

% Present the hybrid methodology and show its need and benefits

\subsection{Hybrid Evaluation Methodology Approach}

\begin{comment}
 - Describe target scenario: dense sensing, single user - single activity
 - Explain in detail the steps: survey, script writing, sensor modelling, synthetic dataset generator 
\end{comment}

The hybrid evaluation methodology has been specially designed for activity recognition systems which assume the \textbf{dense sensing paradigm} introduced by Chen et al. in \cite{Chen2012}, where an action of a user interacting with an object is detected through the sensor attached to the object. Even though the methodology itself is not limited to concrete scenarios, the implementation presented in this paper works for single user - single activity scenarios, i.e. only one user is considered and concurrent or interleaved activities are not taken into account. 

Based on those constraints, the hybrid evaluation methodology has the following steps (see Figure \ref{fig-methodology}):

\begin{enumerate}
 \item Design activity survey: to capture how users perform activities, a proper survey has to be designed. A detailed explanation of how surveys are designed can be found in Section \ref{sec:survey}.
 \item Select target users: depending on the objectives of the research, several user groups can be selected. For example, if the system aims at providing help to elderly people, selecting members of that target group is recommended.
 \item Distribute survey: a suitable way to distribute surveys has to be used, which guarantees users' anonymity. The distribution method can also be influenced by target users. For example, using web-based surveys can be a bad idea if surveys are directed to elderly people, who can be unfamiliar with those technologies. 
 \item Translate surveys to scripts: this step is critical. Appropriate criteria have to be adopted to translate the answers obtained from surveys to scripts for synthetic dataset generator. It is very important not to alter or lose the information provided by users.
 \item Model sensor noise: sensor noise has to be modelled in order to achieve realistic activity datasets. 
 \item Run synthetic dataset generator: using the scripts obtained from surveys and sensor error models, the synthetic dataset generator is executed. The output of the tool is a labelled activity dataset which will serve as the ground truth for evaluation.
 \item Develop the activity recognition system: researchers have to develop the activity recognition system in order to be tested. Notice that datasets generated by the synthetic dataset generator can also be used in this step, specially for data-driven activity recognition systems.
 \item Compare results: finally, the results obtained by the activity recognition system have to be compared with the ground truth, using appropriate metrics.
\end{enumerate}

\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{hybrid_methodology.pdf}
    \caption{The hybrid evaluation methodology steps depicted in a flowchart.}
    \label{fig-methodology}
\end{figure}

\subsection{Survey for Activities of Daily Living}
%\label{sec:survey}
\begin{comment}
 - Explain each of the questions of the survey
 - Show a screenshot and provide the link to the Google Form
 - Google Forms guarantee users' anonymity
 - Explain survey-script translation criteria
\end{comment}

The survey to capture how activities are performed by users has two main parts. The first part is devoted to capture what activities are performed in different days. The second part, on the other hand, asks users about how they perform those activities based on user-object interactions. An example of a survey used by us in some projects can be found in the web\footnote{http://goo.gl/etCNyi}.

For the first part, users are asked to describe their week days in terms of activities. They are expected to provide information about time slots and activity sequences performed in those time slots. Users might also be asked to provide time relations between two consecutive activities. For example, between 7:00 and 7:30 AM a user might make a coffee and ten minutes later might brush teeth. 

The second part is longer. Target activities are presented one by one. For each activity, several questions are asked to users, to capture the locations of activities, the ways activities are performed, the objects used for each activity, a description of how those objects are used and duration estimations.

As described in Section \ref{sec:hybrid-approach}, it is also important to decide the way to circulate the survey and to guarantee user anonymity. In our current experiments, we use Google Forms\footnote{http://www.google.com/google-d-s/createforms.html}, because surveys can be sent by e-mail to target users, users' answers are anonymous and it offers convenient ways to collect and manage received answers. It is worth to point out that even though survey distribution may depend on target users, anonymity should always be preserved. 

% We may introduce some snapshots of the survey to explain what we wan to obtain from that part

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%% SYNTHETIC DATASET GENERATOR
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Synthetic Dataset Generator}
%\label{sec:synthetic}
\begin{comment}
 - Explain the script: sensor activation patterns, activity patterns (sequences and alterations), sensor positive noise
 - Explain probabilistic sensor modelling
 - Explain probabilistic time lapses
 - Show output examples and give numbers
\end{comment}
The synthetic dataset generator tool is central to the hybrid evaluation methodology. The tool has been implemented in Python 2.7\footnote{https://www.python.org/}. The input to the synthetic dataset generator is a script called \textit{ADL script}. 

The first part of the \textit{ADL script} is for defining \textit{sensor activation patterns} for activities. Sensor activation patterns are used to describe how activities are performed in terms of sensor activations. An activity can have an arbitrary number of sensor activation patterns, which are specified with an occurrence probability and a sequence of sensor activations with relative time lapses. An example of sensor activation patterns for activity \textit{MakeCoffee} can be found in Figure \ref{fig:sensor-act}.

\begin{figure}
\begin{small}
\lstset{linewidth=\textwidth}
\begin{lstlisting}
MakeCoffee 2
0.50 storeSens@0 mugSens@5 fridgeSens@10 smilkSens@5 
     afcoffeeSens@5 coffeePotSens@15 potSens@20 
     microwaveSens@20
0.50 storeSens@0 cupSens@5 fridgeSens@10 smilkSens@5 
     afcoffeeSens@5 coffeePotSens@15 potSens@20 
     microwaveSens@20
\end{lstlisting}
\end{small}
\caption{Sensor activation patterns for \textit{MakeCoffee} activity. The activity has two activation patterns with equal probability.}
\label{fig:sensor-act}
\end{figure}

The values that come after the '@' symbol represent the time in seconds between the previous sensor activation and the current one. The synthetic dataset generator establishes a time lapse with a Gaussian random generator whose mean value is the value specified in the script and the standard deviation is the 25\% of the mean. This way, time lapses between two consecutive sensor activations are realistic. 

The second part of the \textit{ADL script} defines the so called \textit{activity patterns}, which represent different days of the user in terms of performed activities. Two kinds of activity patterns are defined: (i) \textit{sequences}, where a time slot is given with a sequence of activities and time lapses between two consecutive activities, and (ii) \textit{alterations}, where a probability value is assigned to an activity to be performed in a concrete time slot. An example is depicted in Figure \ref{fig:activity-pattern}. A typical day of a user is described, with an occurrence probability of 0.29, since the activity pattern describes a weekend day ($2/7 \simeq 0.29$). In this case, the user reported that (s)he sometimes reads a book in the afternoon. Alterations allow modelling this kind of behaviour.


\begin{figure}
\begin{small}
\lstset{linewidth=\textwidth}
\begin{lstlisting}
Prob 0.29 4
S 9:00-10:00 MakeCoffee@0 BrushTeeth@1800 ReadBook@120
S 13:30-14:30 MakePasta@0 BrushTeeth@600
S 22:00-23:00 BrushTeeth@0 WashHands@10
A 18:00-20:00 ReadBook 0.5
\end{lstlisting}
\end{small}
\caption{An example of an activity pattern, which has an occurrence probability of 0.29 and it is composed of three sequences and an alteration.}
\label{fig:activity-pattern}
\end{figure}

The third part of the script is to define \textit{positive sensor noise}, which models the probability for a concrete sensor to get activated in an hour interval independently of ongoing activities. Positive sensor noise is used to model sensor errors and user's erratic behaviour. Erratic behaviour refers to user-object interactions that are not part of an activity. Imagine a user wants to prepare some pasta. Once the store has been open, to grab pasta a coffee recipient has to be moved. This interaction will be registered by the sensor attached to the coffee recipient, but it is not part of the activity. To model sensor positive noise, a probability is assigned to concrete sensors. Synthetic activity generator will use those probabilities to produce noise each hour, using a uniform probability distribution. 

But to model sensor errors, positive sensor noise is not enough. Sometimes, sensors that should get activated, fail. To model those errors another file is used: the context model file. This file is a \textit{Json}\footnote{http://www.json.org/} file where objects of the environment, attached sensors and sensor error models are defined. The file is used to acquire sensor error models, which in our case, have been obtained from the analysis given in \cite{Chen2012a}. Using this information, synthetic dataset generator introduces a failing probability to any sensor that has to be activated, achieving more realistic datasets. %Finally, the \textit{ADL script} contains the number of days to be simulated under those conditions. 

Using the \textit{ADL script} and the context model file, the synthetic dataset generator creates a CSV file where each sensor activation has an associated time-stamp and is labelled with an activity name or with special label \textit{None} if it is caused by noise. Additionally, activity start and end time are marked in the dataset.

\subsection{Discussion about the Hybrid Methodology}
%\label{sec:discussion}
\begin{comment}
- Explain the advantages: generate virtually infinite datasets, arbitrary number of days, perfectly labelled, sensor noise, erratic behaviour, realistic time lapses
 - Explain the main disadvantages: erratic behaviour difficult to capture
 \end{comment}
The methodology explained in Section \ref{sec:hybrid-approach} and implemented through Sections \ref{sec:survey} and \ref{sec:synthetic} has several advantages over the standard methodology explained in Section \ref{sec:introduction}. Let us enumerate and justify the advantages:

\begin{enumerate}
 \item The hybrid methodology is cheap and fast: it does not need to acquire or build any special environment, which can be an important investment. 
 \item A lot of users' information can be used: as it is based on surveys, it is generally easy to achieve a great number of users for the tests.
 \item Ethical and legal issues are much softer: in contrast with the standard methodology, there are no experiments with human beings. The only important point to be considered is the anonymity of users.
 \item Datasets can be generated on demand: using the synthetic dataset generator, arbitrary number of datasets can be generated as needed.
 \item Perfectly labelled datasets can be obtained: the synthetic dataset generator labels all sensor activations according to the given script and sensor error models. In consequence, the generated dataset is a perfect ground truth. 
 \item The influence of researchers is minimised: using surveys, researchers cannot write their own scripts with their bias. Even though researchers are still responsible of writing the scripts, following appropriate survey-script translation criteria, researchers' influence in the datasets is minimised.
 \item Any kind of scenarios can be implemented: the synthetic dataset generator allows preparing experiments where no sensor noise exist, where only a concrete kind of sensor noise exists or where conditions are as close as possible to realistic settings. The chance of implementing all those varieties of scenarios allows researchers test deeper their activity recognition systems, since they can see the influence of any factor they consider relevant. 
\end{enumerate}

However, there are some disadvantages also. For example, modelling user erratic behaviour is not easy. Although synthetic dataset generator offers a way to model this kind of interaction, it cannot capture it accurately. Another disadvantage refers to the information provided in surveys. Some users are very precise in their answers, but some are not. Sometimes, important details of activities are omitted by users in their answers, hence the precise way of performing activities cannot always be captured.