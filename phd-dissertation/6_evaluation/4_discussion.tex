\section{Discussion}
\label{sec:evaluation:discussion}

\subsection{Discussion about SA³}

Results shown in Section \ref{subsubsec:evaluation:sa3:results} show that $SA^3$ can handle varying order of actions in activity performance without any problem. All four set-ups contain different activation patterns, where actions are executed in different orders. This can be seen in Figure \ref{fig:basic-script-activities}: every activity has different sensor activation sequences with varying orders. As the ideal scenario shows (Table \ref{tab-sa3-ideal}), the success rate of the algorithm for every activity is 100\% and neither false positives nor negatives are observed. Notice that sensor activation sequences used for each activity contain many actions which are not used to define any of the IAMs, but the algorithm still performs perfectly when detecting activities. Hence, $SA^3$ can also handle non-considered actions.

As far as noisy scenarios regard, results suggest that missing sensor activations cannot be properly handled by the algorithm, when those activations are linked to actions that are used to define IAMs, i.e. if a sensor activation which is mapped to one of the actions used to define the IAM of a concrete activity fails, that activity cannot be detected by $SA³$. The non-captured activities are proportional to the missing activation probability of those actions, as shown in Figure \ref{fig:sa3-missing}. This is due to the completeness criterion used in the second step of $SA^3$, as explained in Section \ref{sec:clustering:sa3}, which demands the presence of all actions in the IAM of an activity to consider an action sequence a valid activity. However, missing sensor noise only affects true positive rates of the activities which are faultily registered by sensors. False positive and negative rates keep behaving as the ideal scenario. Moreover, a non-detection of an activity does not have any other effect on the other activities. Following this reasoning, a good way to minimise the impact of sensor missing noise is to monitor key objects for IAMs using robust sensors such as contact sensors.  

Independently from such robust monitoring strategies, it is reasonable to think whether algorithmic solutions to mitigate sensor missing noise can be adopted. The completion criterion is very restrictive in that sense, but it is also very reasonable, since if not, distinguishing real activity executions from positive noise would be very difficult, specially considering the low number of actions used in the IAMs (see Table \ref{tab-avg-actions-comp-t2}). Further approaches have not been analysed in this dissertation, because the low level of missing sensor noise in real environments makes the detection rates very good. However, some ideas are suggested in Chapter \ref{cha:conclusions} for their future development.

For sensor positive noise, the scenario is different. $SA^3$ has shown to perform reliably even with high levels of noise. For example, even having certain sensors with faulty activation probabilities of 0.25 per hour, average true positive rate over all activities is 99.9\%. Simultaneously, false positive rates are still very low, concretely 0.3\% in average, while false negative rates are 0. False positive activity detections are due to random occurrences of actions in time instants which make them compatible with the duration criterion of an activity. The probability of having such false positives increases as the noise level increases and the number of actions in IAMs decreases. However, the results obtained with the highest level of noise of the experiments show how robust $SA³$ is in such scenarios.

Finally, a test involving challenging activity models showed that as far as activity models are unique, $SA^3$ does not have any problem detecting them. Average true positive rate for all activities is 100\% and false positive and negative rates are 0, as it can be seen in Table \ref{tab-sa3-demanding}. Remember that the experiments for challenging or demanding activity models were performed without any noise. So results suggest that the performance is exactly the same as for the ideal scenario. 

In conclusion, $SA³$ has been tested for all the desired requirements listed in Section \ref{subsubsec:evaluation:sa3:scenarios}. From the activity models point of view: (i) several variations for every activity, (ii) different probability distributions between activity variations, (iii) varied order of actions in activities and (iv) varied time lapses between consecutive sensor activations. From the behaviour model perspective: (i) different day types, (ii) activities which are very close in time and (iii) combinations of sequences and alterations. All those features were present in all four evaluation scenarios, where ideal conditions, noisy scenarios and demanding activity models were also tested. Results suggest that $SA³$ is a very reliable tool to detect activity executions. It does not correctly label all the sensor activations, but it accurately captures activity time locations. Thus, it can be concluded that $SA³$ serves as a initialisation step for an activity clustering process.

\subsection{Discussion about the clustering process}

The first discussion point for the clustering process is the difference in performance of the three time metrics. Tables \ref{tab-r-comparative-ideal} and \ref{tab-r-comparative-complete} show a clear comparative, both in the ideal and complete scenario. It can be seen that the difference between simple time distance and normalised time distance is not significant. But using dynamic centre normalised time distance for previous activity and normalised time distance for next activity, yields better results. Notice that even though differences are not very big, the higher precision of the third approach is due to lower false positive rates. For some activities, the first two approaches produce even higher true positives, but at the expense of generating much more false positives. Recall values are very similar for all three time metrics in both scenarios. So it can be claimed that as far as sensor activation labelling regards, combining the dynamic centre normalised time distance and normalised time distance is the best option.

The small differences between three time approaches shown in Tables \ref{tab-r-comparative-ideal} and \ref{tab-r-comparative-complete} means that for outsider actions, the candidate function solves the vast majority of the cases (equation \ref{eq-candidate}). For those outsiders that cannot be classified by the candidate function, the three time metrics play a role. But their effect is minimised because of the low number of such outsiders.

For the rest of the discussion about the clustering process, the third time approach will be considered, since it is the best approach. Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show the good performance of the activity clustering process using context knowledge. True positive rate is very high for all activities. The lowest rate is found for activity ReadBook in the complete scenario: 94.6\%. This is due to two factors: (i) the missing sensor probability for pressure sensors is around 10\% and (ii) the IAM for ReadBook has the action \textit{useFurniture} ($IAM(ReadBook) = \{hasBook, useFurniture\}$); all the objects that are mapped to action \textit{useFurniture} are monitored by pressure sensors, for example, sofa, chair or bed. When pressure sensors fail, $SA^3$ cannot detect the activity and hence, true positive rate decreases. Notice that this happens only because the missing action is part of the IAM of the activity. All other activities, even in the complete scenario, show true positive rates higher than 97\%, reaching in some cases 100\% rates. Those high rates are accompanied with very low rates of false positives and negatives. For example, the highest false positive rate has been found for activity MakePasta in the complete scenario with 5.6\%. 

It is worth to point out the behaviour of the clustering process, divided into two steps. Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show how $SA^3$ labels correctly varying number of sensor activations. This number depends on the relation between the number of sensor activations performed by a user and the number of actions in the IAMs. For instance, if the IAM of activity $A$ has two actions and a concrete user performs in average 9 actions for that activity, $SA^3$ will only label correctly those actions that lie inside the two actions of the IAM. It can be seen that for low action number activities like BrushTeeth and ReadBook, $SA^3$ shows quite a high true positive rate and low false negative rate. However, activities like MakeChocolate or MakePasta have a true positive rate below 60\% and high false negative rates. In any case, in the second step run by $AA$, true positives rise, false negatives get very low and false positives slightly increase, giving similar results for all activities. This means that $SA^3$ discovers activities' time locations very accurately and $AA$ treats insider and outsider actions properly to achieve very good rates building on the results of $SA^3$.

As a conclusion, the clustering process depends on the results of $SA³$, its initialisation step. As such, the clustering process is sensitive to sensor missing noise which affects to actions used in IAMs. However, the complete scenario shows sensor missing noise levels extracted from real deployments and results are very good. Notice that experiments are carried out for eight real users, each of them executing activities in many different ways. The high true positive rates and low false positive and negative rates obtained in such realistic set-ups suggest that the activity clustering process annotates very accurately each sensor activation and thus, action, giving as a result robust activity clusters, even in noisy scenarios. Remember that while sensor missing noise models have been extracted from real deployments, sensor positive noise has been exaggerated in order to provide very challenging conditions. Even in those conditions, many of the built activity clusters will correspond to real activity models, and some others will contain spurious actions, due to false positive annotations. But looking at the low rate of false positives, it can be concluded that correct activity clusters will be dominant. 

\subsection{Discussion about the EAM learning system}

The most important objective of this dissertation is to evaluate the performance of the complete EAM learning system, which is composed by the activity clustering process ($SA³$ + $AA$) and the $AML$ algorithm. For that purpose, $AML$ is run using as inputs the clusters obtained in the clustering process. It has to be seen whether extended activity models for every user are properly learned by the system. To answer this question, results obtained in Section \ref{subsubsec:evaluation:eam:results} are analysed.

%First of all, it is important to remember that the objective of the EAM learning system is to learn properly all activity models really executed by a user. This demands true positive rates of 100\%, which is obtained in all the experiments except for two: the experiments depicted in Tables \ref{tab-rp-ideal-t0} and \ref{tab-rp-ideal-t1}. It is curious to see how the MakeCoffee activity has a true positive rate of 92.86\% using the first two time distances in the ideal scenario. When experiments were analysed more accurately, it was observed that for only one user, one of the learned models lacked an action (\textit{hasMilk} in this case). This failure provoked the decrease of the true positive rate from 100\% to 92.86\%. However, when the complete scenario is run, the true positive rate for all three time approaches is 100\%.

First of all, it is important to remember that the objective of the EAM learning system is to learn properly all activity models really executed by a user. This demands true positive rates of 100\%, which is obtained in all the experiments, regardless the applied noise and used time metrics for the clustering process.  

Having three time approaches for the clustering process places the question of what the effect of those time approaches is in the EAM learning system. Table \ref{tab-aml-comparative-ideal} shows a comparison for the ideal scenario and Table \ref{tab-aml-comparative-complete} for the complete one. While the third time approach is better for the ideal scenario, the same does not happen in the complete one. However, the difference in average precision for the complete scenario is not significant, ranging from 59.87\% to 59.02\%. Remember that true positives, false positives and negatives are relative to the average number of patterns, hence learning an additional activity model for a user makes quite a big difference in the rates. That is why the differences in average precision between three time approaches cannot be considered significant. %As the third time approach is the only one which gets a 100\% of true positives in all the experiments and as the difference with other approaches is not significant in the complete scenario, it can be claimed that it is the best option for the EAM learning system. From now on, the discussion will be focused thus on the third time approach.

Obtained results suggest that $AML$ behaves very robustly regardless the time approach used. Even though the initial number of clusters for time approaches one and two are more than for time approach three, $AML$ is able to detect outliers and fuse them to get always very similar results. So from the point of view of the EAM learning system, it is not easy to say which time approach is the best one. Nevertheless, taking into account that time approach three behaves better for clustering and for EAM learning in the ideal scenario, it seems natural to choose it as the reference time approach. From now on, the discussion will be focused thus on the third time approach.

The desired 100\% rate of true positives obtained by the third time approach comes with high rates of false positives, specially for the complete scenario. Those rates were expected, since the objective of the learning algorithm is to avoid removing any activity pattern that has been actually performed by the user. It is preferable to get false positive patterns than removing any activity pattern that has been really performed. For that purpose, the learning process is conservative when removing and fusing activity patterns. Even with this conservative approach, it has been observed during experiments that the learning process can reduce clusters provided by the clustering process from 17 to 3 in some cases, thus removing many false positives and keeping true positive rates of 100\%. 

Nevertheless, the false positive rates shown in the results have to be properly interpreted. The highest rate can be found for activity MakeChocolate in the complete scenario: 120\%. As shown in Table \ref{tab-rp-comp-t2}, the average number of patterns of the activity MakeChocolate is 1, which means that all 8 users perform the activity in only one way. The false positive rate of 120\% comes from the fact that EAM learning algorithm learns in average 2.2 activity models for MakeChocolate, i.e. it learns additional 1.2 patterns in average. Putting it in that perspective and applying the same interpretation to all activities, false positive rates are assumable.

In addition to the low number of spurious activity models learned, it has to be said that those false positive models are usually easy to discard for an expert for two reasons: (i) they have very low occurrence frequencies and (ii) they usually contain actions that are not generally executed for those activities. For example, for activity MakeChocolate, actions like \textit{hasBacon} have been seen. Notice that those actions cannot be discarded by $AA$ during the clustering process, since they are type and location compatible with MakeChocolate. Such an action is produced by sensor positive noise, which can be observed in the slight false positive increments from ideal scenario to complete scenario in Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2}. Either those actions are insiders that are not properly aggregated by the compatibility function (equation \ref{eq-comp}), or outsiders that fulfil the candidate function (equation \ref{eq-candidate}). 

Adding more knowledge to the context knowledge would allow discarding such actions in $AA$. For example, if object types state that meat (bacon or sausages) is only used to prepare meals, the algorithm could infer that bacon cannot be used for activity MakeChocolate, which is a sub-class of activity MakeDrink and disjunct of activity MakeMeal. But this brings the initial knowledge balance problem: how much knowledge should be initially provided to such a learning system? The answer depends a lot on the domain. If obtaining and modelling knowledge for a concrete domain is easy, adding knowledge is a good idea. However, obtaining and modelling knowledge can be very expensive in certain domains. The approach presented in this dissertation follows the philosophy of minimising initial knowledge as much as possible, presenting the \textit{worst case scenario}. We believe that the results shown in Section \ref{subsubsec:evaluation:eam:results} support this decision. 

Concluding, the EAM learning system is able to learn complete and specialised activity models for different users in realistic scenarios. As demanded in Chapter \ref{cha:introduction}, all the activity variations executed by a user are learned. But this is achieved by means of conservative approaches that also generate false positive activity models. It has been observed that such spurious models are not generally a problem for an expert. It has to be said though, that there are some other spurious models that are very difficult to discard even by an expert. For those cases, adding some spurious models to the knowledge base should not be a big problem, since if the user does not perform that activity model, the recognition system will not detect it. 

The EAM learning system is a solid step towards dynamic and personalised knowledge-based activity models. If the learning approach is applied periodically, the learned activity models would be dynamic. Whenever a user performs an activity differently, the learning system will be able to capture that variation and provide the corresponding activity model. The experiments shown in this dissertation are based on batch learning, but adapting the learning system for incremental learning is only an implementation issue. On the other hand, the EAM learning system also supports personalised activity models. It has been shown that eight real users' personalised ways of performing activities are properly modelled using the same IAMs. Using previous incomplete knowledge about activities, complete and specialised activity models in terms of executed actions are shown to be learned with user generated data.