\section{Discussion}
\label{sec:evaluation:discussion}

The first discussion point is the difference in performance of the three time metrics for the clustering process. Table \ref{tab-r-comparative} shows a clear comparative in the complete scenario. It can be seen that the difference between simple time distance and normalized time distance is not significant. But using dynamic center normalized time distance for previous activity and normalized time distance for next activity, yields better results. Notice that even though differences are not very big, the higher precision of the third approach is due to lower false positive rates. For some activities, the first two approaches produce even higher true positives, but at the expense of generating much more false positives. For the global EAM learning process, a low number of false positives is better, so it can be claimed that the third approach for time distances in the clustering process is the best solution to learn specialized and complete activity models.

The small differences between three time approaches shown in Table \ref{tab-r-comparative} means that for outsider actions, the candidate function solves the vast majority of the cases (equation \ref{eq-candidate}). For those outsiders that cannot be classified by the candidate function, the three time metrics play a role. But their effect is minimized because of the low number of such outsiders.

For the rest of the discussion, the third time approach will be considered, since it is the best approach. Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show the good performance of the activity clustering process using context knowledge. True positive rate is very high for all activities. The lowest rate is found for activity \textit{ReadBook} in the complete scenario: 94.6\%. This is due to two factors: (i) the missing sensor probability for pressure sensors is around 10\% and (ii) the IAM for \textit{ReadBook} has the action \textit{useFurniture} ($IAM(ReadBook) = \{hasBook, useFurniture\}$); all the objects that are mapped to action \textit{useFurniture} are monitored by pressure sensors, for example, sofa, chair or bed. When pressure sensors fail, $SA^3$ cannot detect the activity and hence, true positive rate decreases. Notice that this happens only because the missing action is part of the IAM of the activity. All other activities, even in the complete scenario, show true positive rates higher than 97\%, reaching in some cases 100\% rates. Those high rates are accompanied with very low rates of false positives and negatives. For example, the highest false positive rate has been found for activity \textit{MakePasta} in the complete scenario with 5.6\%. 

It is worth to point out the behavior of the clustering process, divided into two steps. Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show how $SA^3$ labels correctly varying number of sensor activations. This number depends on the relation between the number of sensor activations performed by a user and the number of actions in the IAMs. For instance, if the IAM of activity $A$ has two actions and a concrete user performs in average 9 actions for that activity, $SA^3$ will only label correctly those actions that lie inside the two actions of the IAM. It can be seen that for low action number activities like \textit{BrushTeeth} and \textit{ReadBook}, $SA^3$ shows quite a high true positive rate and low false negative rate. However, activities like \textit{MakeChocolate} or \textit{MakePasta} have a true positive rate below 60\% and high false negative rates. In any case, in the second step run by $AA$, true positives rise, false negatives get very low and false positives slightly increase, giving similar results for all activities. This means that $SA^3$ discovers activities' time locations very accurately and $AA$ treats insider and outsider actions properly to achieve very good rates building on the results of $SA^3$.

As far as learning EAMs concerns, which is the objective of this paper, the first fact shown by Tables \ref{tab-rp-ideal-t2} and \ref{tab-rp-comp-t2} is that true positives for all activities in both scenarios are 100\%. This means that the learning algorithm learns properly all the activity patterns performed by any user even in noisy scenarios. However, specially for the complete scenario, this result comes with high rates of false positives. Those rates were expected, since the objective of the learning algorithm is to avoid removing any activity pattern that has been actually performed by the user. It is preferable to get false positive patterns than removing any activity pattern that has been really performed. For that purpose, the learning process is conservative when removing and fusing activity patterns. Even with this conservative approach, it has been observed during experiments that the learning process can reduce clusters provided by $AA$ from 17 to 3 in some cases, thus removing many false positives and keeping true positive rates of 100\%. 

Nevertheless, the false positive rates shown in the results have to be properly interpreted. The highest rate can be found for activity \textit{MakeChocolate} in the complete scenario: 120\%. As shown in Table \ref{tab-rp-comp-t2}, the average number of patterns of the activity \textit{MakeChocolate} is 1, which means that all 8 users perform the activity in only one way. The false positive rate of 120\% comes from the fact that EAM learning algorithm learns in average 2.2 activity models for \textit{MakeChocolate}, i.e. it learns additional 1.2 patterns in average. Putting it in that perspective and applying the same interpretation to all activities, false positive rates are assumable.

In addition to the low number of spurious activity models learned, it has to be said that those false positive models are usually easy to discard for an expert for two reasons: (i) they have very low occurrence frequencies and (ii) they usually contain actions that are not generally executed for those activities. For example, for activity \textit{MakeChocolate}, actions like \textit{hasBacon} have been seen. Notice that those actions cannot be discarded by $AA$, since they are type and location compatible with \textit{MakeChocolate}. Such an action is produced by sensor positive noise, which can be observed in the slight false positive increments from ideal scenario to complete scenario in Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2}. Either those actions are insiders that are not properly aggregated by the compatibility function (equation \ref{eq-comp}), or outsiders that fulfill the candidate function (equation \ref{eq-candidate}). 

Adding more knowledge to the context knowledge would allow discarding such actions in $AA$. For example, if object types state that meat (bacon or sausages) is only used to prepare meals, the algorithm could infer that bacon cannot be used for activity \textit{MakeChocolate}, which is a sub-class of activity \textit{MakeDrink} and disjunct of activity \textit{MakeMeal}. But this brings the initial knowledge balance problem: how much knowledge should be initially provided to such a learning system? The answer depends a lot on the domain. If obtaining and modeling knowledge for a concrete domain is easy, adding knowledge is a good idea. However, obtaining and modeling knowledge can be very expensive in certain domains. The approach presented in this paper follows the philosophy of minimizing initial knowledge as much as possible, presenting the \textit{worst case scenario}. We believe that the results shown in Section \ref{subsec-results} support this decision.  