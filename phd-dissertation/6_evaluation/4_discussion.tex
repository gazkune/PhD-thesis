\section{Discussion}
\label{sec:evaluation:discussion}

Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show the good performance of the activity clustering process using context knowledge. True positive rate is very high for all activities. The lowest rate is found for activity \textit{ReadBook} in the complete scenario: 94.6\%. This is due to two factors: (i) the missing sensor probability for pressure sensors is around 10\% and (ii) the IAM for \textit{ReadBook} has the action \textit{useFurniture}, which is produced by pressure sensors. All other activities, even in the complete scenario, show true positive rates higher than 97\%, reaching in some cases 100\% rates. Those high rates are accompanied with very low rates of false positives and negatives. For example, the highest false positive rate has been found for activity \textit{MakePasta} in the complete scenario with 5.6\%. 

It is worth to point out the behavior of the clustering process, divided into two steps. Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} show how $SA^3$ labels correctly varying number of sensor activations. This number depends on the relation between the number of sensor activations performed by a user and the number of actions in the IAMs. It can be seen that for low action number activities like \textit{BrushTeeth} and \textit{ReadBook}, $SA^3$ shows quite a high true positive rate and low false negative rate. However, activities like \textit{MakeChocolate} or \textit{MakePasta} have a true positive rate below 60\% and high false negative rates. In any case, in the second step run by $AC$, true positives rise, false negatives get very low and false positives slightly increase. This means that $SA^3$ discovers activities' time locations very accurately and $AC$ treats insider and outsider actions properly to achieve very good rates building on the results of $SA^3$.

As far as learning EAMs concerns, the first fact shown by Tables \ref{tab-rp-ideal-t2} and \ref{tab-rp-comp-t2} is that true positives for all activities in both scenarios are 100\%. This means that the learning algorithm learns properly all the activity patterns performed by any user even in noisy scenarios. However, specially for the complete scenario, this result comes with high rates of false positives. Those rates were expected, since the objective of the learning algorithm is to avoid removing any activity pattern that has been actually performed by the user. It is preferable to get false positive patterns than removing any activity pattern that has been really performed. For that purpose, the learning process is conservative when removing and fusing activity patterns. Even with this conservative approach, it has been observed during experiments that the learning process can reduce clusters provided by $AC$ from 17 to 3 in some cases, thus removing many false positives and keeping true positive rates of 100\%. 

Nevertheless, false positive rates have to be properly interpreted. The highest rate can be found for activity \textit{MakeChocolate} in the complete scenario: 120\%. As shown in the table, the average number of patterns of that activity is 1, which means that all 8 users perform it in only one way. So the EAM learning algorithm learns additional 1.2 patterns in average for the activity \textit{MakeChocolate}. Putting it in that perspective, false positive rates are assumable.

Regarding false positive activity patterns, it has to be said that they are usually easy to discard for an expert for two reasons: (i) they have very low occurrence frequencies and (ii) they usually contain actions that are not generally executed for those activities. For example, for \textit{MakeChocolate}, actions like \textit{hasBacon} have been seen. Those actions cannot be discarded by $AC$, since they are type and location compatible with \textit{MakeChocolate} (please, notice the slight false positive increments from ideal scenario to complete scenario in Tables \ref{tab-r-ideal-t2} and \ref{tab-r-comp-t2} due to noise). Adding more knowledge to the context knowledge would allow discarding such actions in $AC$. But this brings the \textbf{initial knowledge balance problem}: how much knowledge should be initially provided to such a learning system? The answer depends a lot on the domain. The approach presented in this paper follows the philosophy of minimizing initial knowledge as much as possible. We believe results shown in Section \ref{subsec-results} support this decision.  