\section{The Learning Algorithm}
\label{sec:learner:algorithm}

Activity clusters extracted by the clustering process contain all the action sequences performed by a user for each activity. But some of those clusters are spurious, due to sensor noise, user erratic behaviour and clustering errors. The objective of $AML$ is to remove spurious action sequences. For that purpose, a three-step algorithm has been designed and implemented. For all the clusters extracted for an activity, the following steps are performed:

\begin{enumerate}
 \item Remove repeated actions into a sequence: some action sequences contain repeated actions. For instance, consider the sequence $S=\{a, b, a, c\}$. As repeated actions do not add any new information for activity modelling, they are removed. $S$ becomes $S' = \{a, b, c\}$. Notice that this step does not remove any action sequence of an activity. This step can be omitted depending on how activity models are used by the activity recognition system. The work presented in this paper is based on the knowledge-driven approach developed by Chen et al. in \cite{Chen2012a}. This activity recognition system does not consider repeated actions in the recognition phase, so activity models do not have this information. However, if the recognition system is sensitive to repeated actions, the learning algorithm can be easily modified to omit this first step.
 \item Fuse equal action sequences: some action sequences contain the same actions, but in different orders. For example, $S_1 = \{a, b, c \}$ and $S_2 = \{b, c, a\}$. The order of actions is not important for activity models, so both sequences are fused. To detect equal sequences, the Jaccard coefficient is used \cite{A.K.Jain1988}. The Jaccard coefficient between two sequences $A$ and $B$ is defined as:
 \begin{equation}
  Jaccard(A, B) = \frac{A \cap B}{A \cup B}
 \end{equation}
Any two sequences whose Jaccard coefficient is 1 are fused. 
 \item Run Jaccard based outlier detection algorithm, which has been specially designed to learn proper action sequences.
\end{enumerate}

The Jaccard based outlier detection is an iterative algorithm. It calculates the so called \textit{Jaccard Matrix} ($JM$), which is a square matrix of all action sequences that remain after steps 1 and 2. $JM_{i, j}$ stores the Jaccard coefficient for action sequences $i$ and $j$. The diagonal of $JM$ is 1, since two equal action sequences' Jaccard coefficient is 1. Removing diagonal values from $JM$, $\hat{JM}$ is obtained. This matrix has the information of the similarity of all action sequences detected for an activity. To detect outlier action sequences, the median of the values of $\hat{JM}$ and the standard deviation to this median are calculated. Notice that the median is used rather than the mean value, since the median is robust to outliers. Using these two statistics a threshold $\theta$ is calculated, such that:

\begin{equation}
 \theta = max \{ median(\hat{JM}) + std(\hat{JM}), \lambda \}
\end{equation}

The first part of the calculation of $\theta$ captures the relative similarity among all action sequences and establishes an adequate threshold to identify outliers. However, as the Jaccard coefficient is defined in an absolute scale, the second part ($\lambda \in [0, 1]$) has to be added. For relatively short action sequences used in the experiments (the longest ones are around 9 actions), 0.75 has shown to be a good balanced value. $\lambda$ prevents fusing sequences that even being more similar than most of the others, their similarity is not higher than it. Sequences below $\lambda$ are considered too different to be fused. 

The Jaccard based outlier detection algorithm fuses sequences whose Jaccard coefficient is higher than $\theta$, until no sequences can be fused. To fuse, the fusion function has been defined. Given two action sequences $S_1$ and $S_2$ with associated occurrence frequencies $f_1$ and $f_2$, the fusion function returns the sequence whose associated frequency is higher. The new occurrence frequency of the returned action sequence will be the sum of $f_1$ and $f_2$. This fusing heuristic states that the lower frequency sequence is a spurious variation of the higher frequency sequence.

The output of the $AML$ is shown in Figure \ref{fig-aml-output}.

\begin{figure}[htbp]
\begin{small}
\begin{lstlisting}
 "MakePasta": {
     "1": [          
             0.5074626865671642, 
             [
                  "hasPasta", 
                  "useCookingAppliance", 
                  "hasBacon", 
                  "turnOnTap", 
                  "openFridge", 
                  "openStore", 
                  "hasCream", 
                  "useCookingUtensil"
              ]
            ],
     "2": [
             0.49253731343283574, 
             [
                  "hasTomato", 
                  "hasPasta", 
                  "useCookingAppliance", 
                  "turnOnTap", 
                  "openStore", 
                  "useCookingUtensil"
             ]
            ]        
    }, 

\end{lstlisting}
\end{small}
\caption{Example of the output of the $AML$ algorithm. Two specialised and complete models for MakePasta activity are depicted.}
\label{fig-aml-output}
\end{figure}

The $AML$ algorithm is shown in pseudo-code in Algorithm \ref{alg:aml}.

\begin{algorithm}
 \caption{$AML$ algorithm for learning extended activity models}
 \label{alg:aml}
 \begin{algorithmic}
 \REQUIRE activity\_clusters
 \ENSURE learned\_action\_sequences
 \STATE $partially\_annotated\_dataset \leftarrow createDataset(sensor\_activation\_dataset)$
 \STATE $action\_dataset \leftarrow applyTransformFunction(sensor\_activation\_dataset,$ 
 $context\_knowledge)$
 \STATE $IAM\_list \leftarrow obtainIAMS(context\_knowledge)$
 \FORALL{$action \in action\_dataset$}
  \IF{$action \in initial\_activity\_models$}
    \STATE $activities \leftarrow obtainActivities(action, IAM\_list)$
  \ENDIF
  \FORALL{$activity \in activities$}
    \STATE $// \text{ Use duration, completion and location criteria}$
    \STATE $valid\_activities \leftarrow findValidActivities(context\_knowledge)$
  \ENDFOR
 \ENDFOR
 \STATE $partially\_annotated\_dataset \leftarrow findNonOverlappingActivities(valid\_activities)$
 \RETURN $learned\_action\_sequences$
 \end{algorithmic}
\end{algorithm}